{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> 1275380010156c5bbed593c0b0c6e57d1aa5a84b
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.6)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Ryan/Desktop/crime-classifier/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTCrimeClassifier(\n",
      "  (model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (hidden_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n",
      "XLNetCrimeClassifier(\n",
      "  (model): XLNetModel(\n",
      "    (word_embedding): Embedding(32000, 768)\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x XLNetLayer(\n",
      "        (rel_attn): XLNetRelativeAttention(\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ff): XLNetFeedForward(\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation_function): GELUActivation()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import time  \n",
    "import random\n",
    "\n",
    "dataset_dir = \"./data/train_test_val\"\n",
    "\n",
    "DATASET = {\n",
    "    'train': pd.read_csv(dataset_dir + '/train.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "    'test': pd.read_csv(dataset_dir + '/test.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "    'val': pd.read_csv(dataset_dir + '/val.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "}\n",
    "\n",
    "MODEL_NAMES = {\n",
    "    \"bert\": 'google-bert/bert-base-uncased',\n",
    "    \"xlnet\": 'xlnet/xlnet-base-cased',\n",
    "}\n",
    "\n",
    "MODEL_VARIANTS = {\n",
    "    \"bert-pretrained\": 'cc-bert-pretrained-model.pth',\n",
    "    \"xlnet-pretrained\": 'cc-xlnet-pretrained-model.pth',\n",
    "    \"bert-finetuned\": 'cc-bert-finetuned-model.pth',\n",
    "    \"xlnet-finetuned\": 'cc-xlnet-finetuned-model.pth',\n",
    "}\n",
    "\n",
    "MODEL_DIR = \"./models\" \n",
    "\n",
    "LABELS = [\n",
    "\n",
    "    'Murder',\n",
    "    'Homicide',\n",
    "    'Robbery',\n",
    "    'Physical Injuries',\n",
    "    'Rape',\n",
    "    'Theft',\n",
    "    'Carnapping',\n",
    "    'Others'\n",
    "]\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "class BERTCrimeClassifier(nn.Module):\n",
    "    def __init__(self, model_name, batch_size=8, epochs=5, dropout=0.1):\n",
    "        super(BERTCrimeClassifier, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_linear = nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.model.config.hidden_size, len(LABELS))\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        bert_outputs = self.model(ids, attention_mask=mask)\n",
    "        cls_hidden_state = bert_outputs.last_hidden_state[:, 0, :] \n",
    "        hidden_output = self.hidden_linear(cls_hidden_state) \n",
    "        dropped_out = self.dropout(hidden_output)  \n",
    "        logits = self.linear(dropped_out)  \n",
    "        return logits\n",
    "\n",
    "\n",
    "class XLNetCrimeClassifier(nn.Module):\n",
    "    def __init__(self, model_name, sbatch_size=8,epochs=5, dropout=0.1): \n",
    "        super(XLNetCrimeClassifier, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.model.config.hidden_size, len(LABELS))\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        bert_outputs = self.model(ids, attention_mask=mask)\n",
    "        cls_hidden_state = bert_outputs.last_hidden_state[:, 0, :] \n",
    "        dropped_out = self.dropout(cls_hidden_state)\n",
    "        logits = self.linear(dropped_out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "bertCrimeClassifier = BERTCrimeClassifier('google-bert/bert-base-uncased')\n",
    "xlnetCrimeClassifier = XLNetCrimeClassifier('xlnet/xlnet-base-cased')\n",
    "\n",
    "print(bertCrimeClassifier)\n",
    "print(xlnetCrimeClassifier)\n",
    "\n",
    "\n",
    "# Global cache para i-store ang mga loaded na models\n",
    "model_cache = {}\n",
    "\n",
    "def get_model(model_id, model_variant, model_path):\n",
    "    model_name = MODEL_NAMES[model_id]\n",
    "\n",
    "    cache_key = f\"{model_id}-{model_variant}-{model_path}\"\n",
    "\n",
    "    if cache_key in model_cache:\n",
    "        print(f\"Using cached model: {cache_key}\")\n",
    "        return model_cache[cache_key]\n",
    "    \n",
    "    if model_id == \"bert\":\n",
    "        crimeClassifier = BERTCrimeClassifier(model_name)\n",
    "    elif model_id == \"xlnet\": \n",
    "        crimeClassifier = XLNetCrimeClassifier(model_name)\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    # model_path = f'{MODEL_DIR}/{model_variant}/{MODEL_VARIANTS[model_variant]}'\n",
    "    model_path = f'{model_path}'\n",
    "    crimeClassifier.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    crimeClassifier.eval()\n",
    "\n",
    "    model_cache[cache_key] = crimeClassifier\n",
    "\n",
    "    print(f\"Model loaded and cached: {cache_key}\")\n",
    "    return crimeClassifier\n",
    "\n",
    "def get_predictions(input_text, model_id, model_variant, model_path):\n",
    "\n",
    "    crimeClassifier = get_model(model_id, model_variant, model_path)\n",
    "\n",
    "    # Tokenizer\n",
    "    model_name = MODEL_NAMES[model_id]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Classification\n",
    "    start_time = time.time()  # Start the timer\n",
    "\n",
    "    # Encode text\n",
    "    encoded_input_text = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "    # Get raw results\n",
    "    with torch.no_grad():\n",
    "        logits = crimeClassifier(ids=encoded_input_text['input_ids'], mask=encoded_input_text['attention_mask'])\n",
    "\n",
    "    # Apply activation to get probabilities\n",
    "    predictions = logits.flatten().sigmoid()\n",
    "\n",
    "    label_probabilities = [{\"label\": label, \"probability\": float(round(prob.item() * 100, 2))} for label, prob in zip(LABELS, predictions)]\n",
    "\n",
    "    # Sort label probabilities in descending order\n",
    "    label_probabilities = sorted(label_probabilities, key=lambda item: -item[\"probability\"])\n",
    "\n",
    "    # Labels greater than 0.5 threshold\n",
    "    predicted_labels = [(label, f\"{pred*100:.2f}%\") for label, pred in zip(LABELS, predictions) if pred >= THRESHOLD]\n",
    "    \n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = round(end_time - start_time, 4)  # Calculate the duration\n",
    "\n",
    "\n",
    "    # Display results\n",
    "   \n",
    "    print(\"Input: \" + input_text)\n",
<<<<<<< HEAD
    "    \n",
=======
    "    # print(\"Index: \" + str(index))\n",
>>>>>>> 1275380010156c5bbed593c0b0c6e57d1aa5a84b
    "    # get_actual_labels(index)\n",
    "    print()\n",
    "    print(\"Predicted Labels:\")\n",
    "    for label, probability in predicted_labels:\n",
    "        print(f\"({label}, {probability})\")\n",
    "    print()\n",
    "    for result in label_probabilities: \n",
    "        print(f\"{result['label']}: {result['probability']}\")\n",
    "\n",
    "    print(f\"\\nPrediction processing time: {duration:.4f} seconds\")\n",
    "\n",
    "    return label_probabilities, duration   # Return both the predictions and the processing time\n",
    "\n",
    "\n",
    "def get_actual_labels(index=-1): \n",
    "\n",
    "    text = DATASET[\"test\"][\"Text\"][index]\n",
    "\n",
    "    labels = []\n",
    "    for label in LABELS: \n",
    "        actual = DATASET[\"test\"][label][index]\n",
    "        \n",
    "        if actual == 1:\n",
    "           labels.append(label)\n",
    "\n",
    "    print(\"Actual labels:\")\n",
    "    print([class_name for class_name in LABELS if DATASET[\"test\"][class_name][index] == 1])\n",
    "    # print(labels)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached model: xlnet-xlnet-finetuned-./models/xlnet-finetuned/cc-xlnet-finetuned-model.pth\n",
      "Input: A couple was attacked and beaten by two men after they tried to steal their car in the parking lot. Luckily, they managed to escape with only minor injuries, but the attackers took off with their belongings. Crime in this city is getting worse\n",
      "\n",
      "Predicted Labels:\n",
      "(Robbery, 87.72%)\n",
      "(Carnapping, 56.97%)\n",
      "\n",
      "Robbery: 87.72\n",
      "Carnapping: 56.97\n",
      "Physical Injuries: 8.71\n",
      "Theft: 1.26\n",
      "Homicide: 0.8\n",
      "Others: 0.04\n",
      "Murder: 0.0\n",
      "Rape: 0.0\n",
      "\n",
      "Prediction processing time: 0.4436 seconds\n"
     ]
    }
   ],
   "source": [
    "# index = 64 # Palitan ang index (from 0 - 1199) kung gusto niyo ng ibang example \n",
    "# index = random.randint(0, 1199) # or get a random number \n",
    "# EXAMPLE_INPUT = DATASET['test']['Text'][index] \n",
    "# get_actual_labels(index)\n",
    "\n",
    "# or i-uncomment out niyo eto kung gusto niyo magtest ng sariling example\n",
    "EXAMPLE_INPUT = \"A couple was attacked and beaten by two men after they tried to steal their car in the parking lot. Luckily, they managed to escape with only minor injuries, but the attackers took off with their belongings. Crime in this city is getting worse\"\n",
    "# EXAMPLE_INPUT = \"After running a quick errand, I had to park my car on a street next to a construction site where there was poor illumination and not many people around. When I returned, my car was gone, indicating that there had been an auto burglary.\"\n",
    "# print(len(EXAMPLE_INPUT))\n",
    "# 80 - 600 characters\n",
    "\n",
    "xlnet_predictions = get_predictions(EXAMPLE_INPUT, \"xlnet\", \"xlnet-finetuned\",'./models/xlnet-finetuned/cc-xlnet-finetuned-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached model: bert-bert-finetuned-./models/bert-finetuned/cc-bert-finetuned-model.pth\n",
      "Input: I can't believe what happened in my neighborhood last night. A group of armed men broke into a house and robbed the place. Things got out of hand, and one of the homeowners was shot and killed. It's just so terrifying to think about.\n",
      "\n",
      "Predicted Labels:\n",
      "(Murder, 53.75%)\n",
      "\n",
      "Murder: 53.75\n",
      "Homicide: 16.44\n",
      "Others: 12.07\n",
      "Robbery: 8.82\n",
      "Carnapping: 1.52\n",
      "Theft: 1.21\n",
      "Rape: 0.77\n",
      "Physical Injuries: 0.56\n",
      "\n",
      "Prediction processing time: 0.3232 seconds\n"
     ]
    }
   ],
   "source": [
    "# bert_predictions = get_predictions(EXAMPLE_INPUT, \"bert\", \"bert-finetuned\", './models/bert-finetuned/cc-bert-finetuned-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached model: bert-bert-finetuned-../saved_models/October 16, 2024/bert-(10-16-2024)_(02-49-38-PM).pth\n",
      "Input: A couple was attacked and beaten by two men after they tried to steal their car in the parking lot. Luckily, they managed to escape with only minor injuries, but the attackers took off with their belongings. Crime in this city is getting worse\n",
      "\n",
      "Predicted Labels:\n",
      "\n",
      "Physical Injuries: 11.04\n",
      "Robbery: 7.85\n",
      "Others: 3.42\n",
      "Carnapping: 3.37\n",
      "Homicide: 2.96\n",
      "Theft: 1.6\n",
      "Murder: 0.36\n",
      "Rape: 0.26\n",
      "\n",
      "Prediction processing time: 0.2310 seconds\n"
     ]
    }
   ],
   "source": [
    "new_bert_predictions = get_predictions(EXAMPLE_INPUT, \"bert\", \"bert-finetuned\", '../saved_models/October 16, 2024/bert-(10-16-2024)_(02-49-38-PM).pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached model: xlnet-xlnet-finetuned-../saved_models/October 16, 2024/xlnet-(10-16-2024)_(06-51-40-PM).pth\n",
      "Input: A couple was attacked and beaten by two men after they tried to steal their car in the parking lot. Luckily, they managed to escape with only minor injuries, but the attackers took off with their belongings. Crime in this city is getting worse\n",
      "\n",
      "Predicted Labels:\n",
      "\n",
      "Carnapping: 41.78\n",
      "Robbery: 18.98\n",
      "Others: 5.31\n",
      "Physical Injuries: 5.18\n",
      "Homicide: 4.95\n",
      "Theft: 0.63\n",
      "Rape: 0.08\n",
      "Murder: 0.02\n",
      "\n",
      "Prediction processing time: 0.2064 seconds\n"
     ]
    }
   ],
   "source": [
    "new_xlnet_predictions = get_predictions(EXAMPLE_INPUT, \"xlnet\", \"xlnet-finetuned\",  '../saved_models/October 16, 2024/xlnet-(10-16-2024)_(06-51-40-PM).pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "Murder\n",
    "\n",
    "    \"A person was found guilty after a long investigation into the brutal killing of their neighbor. The court sentenced them to life in prison for the cold-blooded murder.\"\n",
    "\n",
    "Homicide\n",
    "\n",
    "    \"The local authorities are investigating a suspected homicide after a body was discovered in an abandoned building with multiple injuries suggesting foul play.\"\n",
    "\n",
    "Robbery\n",
    "\n",
    "    \"The store owner was terrified when two masked individuals entered the shop, brandishing weapons and demanding money. It was a frightening robbery that lasted only a few minutes.\"\n",
    "\n",
    "Physical Injuries\n",
    "\n",
    "    \"During the bar fight, several people were injured, with one person suffering from a broken arm and another with severe cuts. The police are looking for the attackers responsible for the physical injuries.\"\n",
    "\n",
    "Rape\n",
    "\n",
    "    \"The victim bravely came forward to report the incident, describing how they were assaulted in a parking lot. The accused has been charged with rape and is currently in police custody.\"\n",
    "\n",
    "Theft\n",
    "\n",
    "    \"Someone broke into the car last night and stole the stereo system and other valuables. The theft was reported to the police, who are now investigating the incident.\"\n",
    "\n",
    "Carnapping\n",
    "\n",
    "    \"The owner was devastated when they found out their car was missing from the parking lot. The police suspect it is a case of carnapping, as there have been similar incidents in the area.\"\n",
    "\n",
    "Others (non-index)\n",
    "\n",
    "    \"The neighborhood has seen an increase in minor offenses like vandalism and noise complaints, but nothing as serious as the other crimes reported.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Someone broke into the car last night and stole the stereo system and other valuables. The theft was reported to the police, who are now investigating the incident.\n",
      "Index: 561\n",
      "Actual labels:\n",
      "['Murder']\n",
      "\n",
      "Predicted Labels:\n",
      "\n",
      "Others: 37.04\n",
      "Carnapping: 6.08\n",
      "Theft: 4.31\n",
      "Robbery: 3.04\n",
      "Homicide: 0.63\n",
      "Murder: 0.57\n",
      "Physical Injuries: 0.54\n",
      "Rape: 0.52\n",
      "\n",
      "Prediction processing time: 0.1393 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load the best model\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\"./models/bert-classifier-wrapper\" + \"/checkpoint-1500\")\n",
    "\n",
    "\n",
    "\n",
    "# Tokenizer\n",
    "model_name = MODEL_NAMES[\"bert\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Classification\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "# Encode text\n",
    "encoded_input_text = tokenizer(EXAMPLE_INPUT, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Get raw results\n",
    "with torch.no_grad():\n",
    "    output = best_model(input_ids=encoded_input_text['input_ids'], \n",
    "                        attention_mask=encoded_input_text['attention_mask'])\n",
    "    logits = output.logits  # Extract logits from the output\n",
    "\n",
    "# Apply activation to get probabilities\n",
    "predictions = logits.sigmoid() \n",
    "predictions = predictions[0]\n",
    "\n",
    "label_probabilities = [{\"label\": label, \"probability\": float(round(prob.item() * 100, 2))} for label, prob in zip(LABELS, predictions)]\n",
    "\n",
    "# Sort label probabilities in descending order\n",
    "label_probabilities = sorted(label_probabilities, key=lambda item: -item[\"probability\"])\n",
    "\n",
    "# Labels greater than 0.5 threshold\n",
    "predicted_labels = [(label, f\"{pred*100:.2f}%\") for label, pred in zip(LABELS, predictions) if pred >= THRESHOLD]\n",
    "\n",
    "end_time = time.time()  # End the timer\n",
    "duration = round(end_time - start_time, 4)  # Calculate the duration\n",
    "\n",
    "\n",
    "# Display results\n",
    "\n",
    "print(\"Input: \" + EXAMPLE_INPUT)\n",
    "print(\"Index: \" + str(index))\n",
    "get_actual_labels(index)\n",
    "print()\n",
    "print(\"Predicted Labels:\")\n",
    "for label, probability in predicted_labels:\n",
    "    print(f\"({label}, {probability})\")\n",
    "print()\n",
    "for result in label_probabilities: \n",
    "    print(f\"{result['label']}: {result['probability']}\")\n",
    "\n",
    "print(f\"\\nPrediction processing time: {duration:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
