{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/syke/Colorful/Github/xlnet/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import time  \n",
    "import random\n",
    "\n",
    "dataset_dir = \"./data/train_test_val\"\n",
    "\n",
    "DATASET = {\n",
    "    'train': pd.read_csv(dataset_dir + '/train.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "    'test': pd.read_csv(dataset_dir + '/test.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "    'val': pd.read_csv(dataset_dir + '/val.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "}\n",
    "\n",
    "MODEL_NAMES = {\n",
    "    \"bert\": 'google-bert/bert-base-uncased',\n",
    "    \"xlnet\": 'xlnet/xlnet-base-cased',\n",
    "}\n",
    "\n",
    "MODEL_VARIANTS = {\n",
    "    \"bert-pretrained\": 'cc-bert-pretrained-model.pth',\n",
    "    \"xlnet-pretrained\": 'cc-xlnet-pretrained-model.pth',\n",
    "    \"bert-finetuned\": 'cc-bert-finetuned-model.pth',\n",
    "    \"xlnet-finetuned\": 'cc-xlnet-finetuned-model.pth',\n",
    "}\n",
    "\n",
    "MODEL_DIR = \"./models\" \n",
    "\n",
    "LABELS = [\n",
    "\n",
    "    'Murder',\n",
    "    'Homicide',\n",
    "    'Robbery',\n",
    "    'Physical Injuries',\n",
    "    'Rape',\n",
    "    'Theft',\n",
    "    'Carnapping',\n",
    "    'Others'\n",
    "]\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "class BERTCrimeClassifier(nn.Module):\n",
    "    def __init__(self, model_name, batch_size=8, epochs=5, dropout=0.1):\n",
    "        super(BERTCrimeClassifier, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_linear = nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.model.config.hidden_size, len(LABELS))\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        bert_outputs = self.model(ids, attention_mask=mask)\n",
    "        cls_hidden_state = bert_outputs.last_hidden_state[:, 0, :] \n",
    "        hidden_output = self.hidden_linear(cls_hidden_state) \n",
    "        dropped_out = self.dropout(hidden_output)  \n",
    "        logits = self.linear(dropped_out)  \n",
    "        return logits\n",
    "\n",
    "\n",
    "class XLNetCrimeClassifier(nn.Module):\n",
    "    def __init__(self, model_name, sbatch_size=8,epochs=5, dropout=0.1): \n",
    "        super(XLNetCrimeClassifier, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.model.config.hidden_size, len(LABELS))\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        bert_outputs = self.model(ids, attention_mask=mask)\n",
    "        cls_hidden_state = bert_outputs.last_hidden_state[:, 0, :] \n",
    "        dropped_out = self.dropout(cls_hidden_state)\n",
    "        logits = self.linear(dropped_out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "bertCrimeClassifier = BERTCrimeClassifier('google-bert/bert-base-uncased')\n",
    "xlnetCrimeClassifier = XLNetCrimeClassifier('xlnet/xlnet-base-cased')\n",
    "\n",
    "print(bertCrimeClassifier)\n",
    "print(xlnetCrimeClassifier)\n",
    "\n",
    "\n",
    "# Global cache para i-store ang mga loaded na models\n",
    "model_cache = {}\n",
    "\n",
    "def get_model(model_id, model_variant):\n",
    "    model_name = MODEL_NAMES[model_id]\n",
    "\n",
    "    cache_key = f\"{model_id}-{model_variant}\"\n",
    "\n",
    "    if cache_key in model_cache:\n",
    "        print(f\"Using cached model: {cache_key}\")\n",
    "        return model_cache[cache_key]\n",
    "    \n",
    "    if model_id == \"bert\":\n",
    "        crimeClassifier = BERTCrimeClassifier(model_name)\n",
    "    elif model_id == \"xlnet\": \n",
    "        crimeClassifier = XLNetCrimeClassifier(model_name)\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    model_path = f'{MODEL_DIR}/{model_variant}/{MODEL_VARIANTS[model_variant]}'\n",
    "    crimeClassifier.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    crimeClassifier.eval()\n",
    "\n",
    "    model_cache[cache_key] = crimeClassifier\n",
    "\n",
    "    print(f\"Model loaded and cached: {cache_key}\")\n",
    "    return crimeClassifier\n",
    "\n",
    "def get_predictions(input_text, model_id, model_variant):\n",
    "\n",
    "    crimeClassifier = get_model(model_id, model_variant)\n",
    "\n",
    "    # Tokenizer\n",
    "    model_name = MODEL_NAMES[model_id]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Classification\n",
    "    start_time = time.time()  # Start the timer\n",
    "\n",
    "    # Encode text\n",
    "    encoded_input_text = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "    # Get raw results\n",
    "    with torch.no_grad():\n",
    "        logits = crimeClassifier(ids=encoded_input_text['input_ids'], mask=encoded_input_text['attention_mask'])\n",
    "\n",
    "    # Apply activation to get probabilities\n",
    "    predictions = logits.flatten().sigmoid()\n",
    "\n",
    "    label_probabilities = [{\"label\": label, \"probability\": float(round(prob.item() * 100, 2))} for label, prob in zip(LABELS, predictions)]\n",
    "\n",
    "    # Sort label probabilities in descending order\n",
    "    label_probabilities = sorted(label_probabilities, key=lambda item: -item[\"probability\"])\n",
    "\n",
    "    # Labels greater than 0.5 threshold\n",
    "    predicted_labels = [(label, f\"{pred*100:.2f}%\") for label, pred in zip(LABELS, predictions) if pred >= THRESHOLD]\n",
    "    \n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = round(end_time - start_time, 4)  # Calculate the duration\n",
    "\n",
    "\n",
    "    # Display results\n",
    "   \n",
    "    print(\"Input: \" + input_text)\n",
    "    print(\"Index: \" + str(index))\n",
    "    # get_actual_labels(index)\n",
    "    print()\n",
    "    print(\"Predicted Labels:\")\n",
    "    for label, probability in predicted_labels:\n",
    "        print(f\"({label}, {probability})\")\n",
    "    print()\n",
    "    for result in label_probabilities: \n",
    "        print(f\"{result['label']}: {result['probability']}\")\n",
    "\n",
    "    print(f\"\\nPrediction processing time: {duration:.4f} seconds\")\n",
    "\n",
    "    return label_probabilities, duration   # Return both the predictions and the processing time\n",
    "\n",
    "\n",
    "def get_actual_labels(index=-1): \n",
    "\n",
    "    text = DATASET[\"test\"][\"Text\"][index]\n",
    "\n",
    "    labels = []\n",
    "    for label in LABELS: \n",
    "        actual = DATASET[\"test\"][label][index]\n",
    "        \n",
    "        if actual == 1:\n",
    "           labels.append(label)\n",
    "\n",
    "    print(\"Actual labels:\")\n",
    "    print([class_name for class_name in LABELS if DATASET[\"test\"][class_name][index] == 1])\n",
    "    # print(labels)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/syke/Colorful/Github/xlnet/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached model: xlnet-xlnet-finetuned\n",
      "Input: after a massive outdoor concert the sky opened up pouring rain on the sea of attendees scrambling to find their cars amid the chaos and umbrellas i found my parking spot empty i had parked near the back entrance thinking it would be easier to leave quickly the rain soaked lot was a mess and i realized too late that the car which i had parked next to a large van was gone the van was still there blocking the view from any nearby cameras making it easy for auto burglary to work unnoticed\n",
      "Index: 63\n",
      "\n",
      "Predicted Labels:\n",
      "(Carnapping, 99.95%)\n",
      "\n",
      "Carnapping: 99.95\n",
      "Theft: 0.9\n",
      "Robbery: 0.41\n",
      "Physical Injuries: 0.11\n",
      "Homicide: 0.09\n",
      "Others: 0.03\n",
      "Murder: 0.01\n",
      "Rape: 0.01\n",
      "\n",
      "Prediction processing time: 0.5444 seconds\n"
     ]
    }
   ],
   "source": [
    "# index = 64 # Palitan ang index (from 0 - 1199) kung gusto niyo ng ibang example \n",
    "index = random.randint(0, 1199) # or get a random number \n",
    "EXAMPLE_INPUT = DATASET['test']['Text'][index] \n",
    "# get_actual_labels(index)\n",
    "\n",
    "# or i-uncomment out niyo eto kung gusto niyo magtest ng sariling example\n",
    "# EXAMPLE_INPUT = \"oh no a girl was found harassed by an old man\"\n",
    "EXAMPLE_INPUT = \"The neighborhood has seen an increase in minor offenses like vandalism and noise complaints, but nothing as serious as the other crimes reported.\"\n",
    "# print(len(EXAMPLE_INPUT))\n",
    "# 80 - 600 characters\n",
    "\n",
    "xlnet_predictions = get_predictions(EXAMPLE_INPUT, \"xlnet\", \"xlnet-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bert_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m(EXAMPLE_INPUT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "bert_predictions = get_predictions(EXAMPLE_INPUT, \"bert\", \"bert-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "Murder\n",
    "\n",
    "    \"A person was found guilty after a long investigation into the brutal killing of their neighbor. The court sentenced them to life in prison for the cold-blooded murder.\"\n",
    "\n",
    "Homicide\n",
    "\n",
    "    \"The local authorities are investigating a suspected homicide after a body was discovered in an abandoned building with multiple injuries suggesting foul play.\"\n",
    "\n",
    "Robbery\n",
    "\n",
    "    \"The store owner was terrified when two masked individuals entered the shop, brandishing weapons and demanding money. It was a frightening robbery that lasted only a few minutes.\"\n",
    "\n",
    "Physical Injuries\n",
    "\n",
    "    \"During the bar fight, several people were injured, with one person suffering from a broken arm and another with severe cuts. The police are looking for the attackers responsible for the physical injuries.\"\n",
    "\n",
    "Rape\n",
    "\n",
    "    \"The victim bravely came forward to report the incident, describing how they were assaulted in a parking lot. The accused has been charged with rape and is currently in police custody.\"\n",
    "\n",
    "Theft\n",
    "\n",
    "    \"Someone broke into the car last night and stole the stereo system and other valuables. The theft was reported to the police, who are now investigating the incident.\"\n",
    "\n",
    "Carnapping\n",
    "\n",
    "    \"The owner was devastated when they found out their car was missing from the parking lot. The police suspect it is a case of carnapping, as there have been similar incidents in the area.\"\n",
    "\n",
    "Others (non-index)\n",
    "\n",
    "    \"The neighborhood has seen an increase in minor offenses like vandalism and noise complaints, but nothing as serious as the other crimes reported.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Someone broke into the car last night and stole the stereo system and other valuables. The theft was reported to the police, who are now investigating the incident.\n",
      "Index: 561\n",
      "Actual labels:\n",
      "['Murder']\n",
      "\n",
      "Predicted Labels:\n",
      "\n",
      "Others: 37.04\n",
      "Carnapping: 6.08\n",
      "Theft: 4.31\n",
      "Robbery: 3.04\n",
      "Homicide: 0.63\n",
      "Murder: 0.57\n",
      "Physical Injuries: 0.54\n",
      "Rape: 0.52\n",
      "\n",
      "Prediction processing time: 0.1393 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load the best model\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\"./models/bert-classifier-wrapper\" + \"/checkpoint-1500\")\n",
    "\n",
    "\n",
    "\n",
    "# Tokenizer\n",
    "model_name = MODEL_NAMES[\"bert\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Classification\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "# Encode text\n",
    "encoded_input_text = tokenizer(EXAMPLE_INPUT, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Get raw results\n",
    "with torch.no_grad():\n",
    "    output = best_model(input_ids=encoded_input_text['input_ids'], \n",
    "                        attention_mask=encoded_input_text['attention_mask'])\n",
    "    logits = output.logits  # Extract logits from the output\n",
    "\n",
    "# Apply activation to get probabilities\n",
    "predictions = logits.sigmoid() \n",
    "predictions = predictions[0]\n",
    "\n",
    "label_probabilities = [{\"label\": label, \"probability\": float(round(prob.item() * 100, 2))} for label, prob in zip(LABELS, predictions)]\n",
    "\n",
    "# Sort label probabilities in descending order\n",
    "label_probabilities = sorted(label_probabilities, key=lambda item: -item[\"probability\"])\n",
    "\n",
    "# Labels greater than 0.5 threshold\n",
    "predicted_labels = [(label, f\"{pred*100:.2f}%\") for label, pred in zip(LABELS, predictions) if pred >= THRESHOLD]\n",
    "\n",
    "end_time = time.time()  # End the timer\n",
    "duration = round(end_time - start_time, 4)  # Calculate the duration\n",
    "\n",
    "\n",
    "# Display results\n",
    "\n",
    "print(\"Input: \" + EXAMPLE_INPUT)\n",
    "print(\"Index: \" + str(index))\n",
    "get_actual_labels(index)\n",
    "print()\n",
    "print(\"Predicted Labels:\")\n",
    "for label, probability in predicted_labels:\n",
    "    print(f\"({label}, {probability})\")\n",
    "print()\n",
    "for result in label_probabilities: \n",
    "    print(f\"{result['label']}: {result['probability']}\")\n",
    "\n",
    "print(f\"\\nPrediction processing time: {duration:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
